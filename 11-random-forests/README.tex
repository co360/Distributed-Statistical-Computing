\section{Mahout实例：随机森林的分布式实现}\label{ux5b9eux4f8bux5206ux6790ux968fux673aux68eeux6797ux7684ux5e76ux884cux5b9eux73b0}

\subsection{准备知识}\label{ux51c6ux5907ux77e5ux8bc6}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  随机森林
\item
  Mahout
\item
  Spark
\end{itemize}

\subsection{研究背景}\label{ux7814ux7a76ux80ccux666f}

切伦科夫望远镜的目标是接收伽玛射线，其光子能量是可见光的亿亿倍。本
文主要收集由 MC 生成的模 拟大气切伦科夫望远镜接收的高能伽玛射线粒子的
大量数据，通过其属性指标判断其属于 gamma(sighal)事件，还是 hadron
(background)事件；是一个二分类问题。

\subsection{数据来源}\label{ux6570ux636eux6765ux6e90}

数据来自 UCI 的大气切伦科夫望远镜项目（网址：
\href{http://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data}{\lstinline|http://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data|}）。数据
集共有 19020 个样本观测值，11 个变量。在服务器上，使用下面的 Linux
命令直接下载数据。其中 \texttt{URL\_address\_of\_data} 为该数据集的网址。

\begin{lstlisting}
	$ wget -t inf URL_address_of_data
\end{lstlisting}

\subsection{建立模型}\label{ux5efaux7acbux6a21ux578b}

基于分类问题的机器学习算法主要包括逻辑回归、朴素贝叶斯、决策树、神
经网络、隐马尔科夫以及
建立在决策树之上的推广算法------随机森林,Boosting, Bagging
等等。决策树是一种简单易解释的模型，在实际中运用非常广泛，但是
它自身存在很多缺点。随机森林是决策树的一种推广：它是一个包含多个决
策树的分类器，并且输出的类别是由个别树输出的类别的众数而定。随机森林提高了
决策树的准确率，
速度快且易于进行并行计算。本文中对训练数据建立随机森林模型，并在测试集上计算误判率比较模型
的 优劣。

\subsubsection{基于Mahout的实现}\label{ux57faux4e8emahoutux7684ux5b9eux73b0}

\paragraph{划分训练集、测试集}\label{ux5212ux5206ux8badux7ec3ux96c6ux6d4bux8bd5ux96c6}

在下载好的数据文件路径下，调用 Mahout 实现训练集、测试集的划分(70\%
为训练集、30\%为测试集)。 具体命令如下：

\begin{lstlisting}
	$ mahout splitDataset -i magic04.data -o splitdata \
	   -t 0.7 -p 0.3
\end{lstlisting}

划分后的训练集与测试集分别位于 splitdata 路径下的 trainingData 与
testData 中。这里需要注 意的是，直接调用 Mahout
命令需要提前设置环境变量，否则，需要用\texttt{/home/dmc/mahout/bin/mahout} 代 替
\texttt{mahout}。

\paragraph{数据上传至 HDFS}\label{ux6570ux636eux4e0aux4f20ux81f3-hdfs}

首先在 Hadoop 文件系统中创建一个文件夹 pkuzcy
用于进行本次实验。之后上传的数据集以及建模结果都存放在这里。

\begin{lstlisting}
	$ hadoop fs –mkdir pkuzcy
\end{lstlisting}

注意，这里直接调用 Hadoop 命令的前提是设置好环境变量
（\lstinline{/home/dmc/hadoop/bin/}路径下的 hadoop）。如果没有设置，需要用
\lstinline{/home/dmc/hadoop/bin/hadoop} 代替 hadoop。上传文件至 HDFS：这样就把训练
集与测试集分别上传至文件系统中的 pkuzcy 路径下，可以用 下面的命令查看：

\begin{lstlisting}
	$ hadoop fs –ls pkuzcy
\end{lstlisting}

\paragraph{生成数据集描述}\label{ux751fux6210ux6570ux636eux96c6ux63cfux8ff0}

下载的数据集文本文件只有数据，没有相关数据的描述。在用 Mahout 建立
随机森林模型之前，先对其构 建描述信息。

\begin{lstlisting}
	$ hadoop jar $MAHOUT_HOME/mahout-examples-0.10.1-job.jar \
	org.apache.mahout.classifier.df.tools.Describe \
	-p pkuzcy/train.arff \
	-f pkuzcy/train.info \
	-d 10 N L
\end{lstlisting}

这里，\path{$MAHOUT_HOME} 代表\texttt{/home/dmc/mahout}，参数 \lstinline|-p| 表示输入文
件，\lstinline|-f|表示输出文件；在 Hadoop 平台 上调用 Mahout，输入输出均为 HDFS 文件系统中
的数据。\lstinline|-d| 表示要描述的数据集的变量信息，其后的 字符串``10 N L''表示从左到 右依
次是 10个数值型变量，最后的``L''表示要分类的变量。这里还可以输入``C''表示分类型变量(本例中
没有分类型)。成功执行后，文件系统中 pkuzcy路径下会出现 train.info 的文件。使
用 \lstinline|cat| 命 令查看该路径下所有的 info文件。

\begin{lstlisting}
	$ hadoop fs -cat pkuzcy/*.info
\end{lstlisting}

\paragraph{训练模型}\label{ux8badux7ec3ux6a21ux578b}

在训练集上建立随机森林模型，具体命令如下：

\begin{lstlisting}
	$ hadoop jar $MAHOUT_HOME/mahout-examples-0.10.1-job.jar \
	org.apache.mahout.classifier.df.mapreduce.BuildForest \
	-Dmapred.max.split.size=147739 \
	-d pkuzcy/train.arff \
	-ds pkuzcy/train.info \
	-sl 5 –p -t 100 -o magicForest
\end{lstlisting}

这里的 Dmapred.max.split.size 参数表示 Hadoop 分布式计算每部分数据的最
大规模，默认为原始数据的十分之一，这里使用 147739 即为原始训练集的 1/10。
参数\texttt{-sl} 表示每棵树的使用随机的 5 个变量来构建；参数\texttt{-p} 表示分布式计算；参
数\texttt{-t} 表示子树的数量,这里取 100 棵；参数\texttt{-o} 表示建立好的模型存放在
\texttt{magicForest} 路径下。

\begin{lstlisting}
	$ hadoop jar $MAHOUT_HOME/mahout-examples-0.10.1-job.jar \
	org.apache.mahout.classifier.df.mapreduce.TestForest \
	-i pkuzcy/test.arff \
	-ds pkuzcy/train.info \
	-m magicForest \
	-a -mr -o prediction
\end{lstlisting}

这里测试集的描述使用的是同训练集一样的描述信息。参数\texttt{-m} 表示使用的
模型，即为上面建立的模型 magicForest；参数\texttt{-a} 表示计算混淆矩阵；参数\texttt{-mr}
表示采用分布式计算；参数\texttt{-o} 表示预测结果存放在 \texttt{prediction}
路径下。输出的信息也有很多，包括文件系统读入、写出的数据量，Map 的个数，计
算时间，混 淆矩阵，正确、错误判断分类的比率等。混淆矩阵显示正确分类 4959
个样本，准确率为 87.77\%；错分 了 691 个样本，错分率为 12.23\%。

\paragraph{训练误差}\label{ux8badux7ec3ux8befux5dee}

在原训练集上检验一下建立的模型，将输入数据文件改为 train.arff，结果输 出到
\texttt{prediction-train} 路径，其余参数不变。结果显示正确分类 13247
个样本，准确率为 99.08\%；错分了 123 个样本，错分率为
0.92\%。比之测试集，正确率高了很多，模型可能存在过拟合现象。

\paragraph{1000
棵子树的随机森林}\label{ux68f5ux5b50ux6811ux7684ux968fux673aux68eeux6797}

更改子树数量参数，构建 1000
棵决策树再次建立模型，并在测试集上检验。结果显示正确分类 4974 个
样本，准确率为 88.04\%；错分了 676 个样本，错分率为11.96\%。与上面 100
棵树的模型比较，准确率有
一点提高，但是子树数量的增多增加了计算的代价，运行时间反而增多。所以根据结果可知，采用
100 棵 树建立随机 森林模型已经足够。

\subsubsection{基于Spark的实现}\label{ux57faux4e8esparkux7684ux5b9eux73b0}

Spark 拥有多种语言的函数式编程 API，提供了除 Map 和 Reduce 之外更多的
运算符，这些操作是通过 一个称作弹性分布式数据集(resilient distributed
datasets, RDDs)的分布式数据框架进行的。由于 RDD 可以被缓存在内存中，Spark
对迭代 应用特别有效。Spark 非常快，可以通过类似 Python REPL 的
命令行提示符交互 式访问。Spark 的核心组件之一 MLlib
是一个常用的机器学习算法库，算法被实现 为 对 RDD 的 Spark
操作。这个库包含可扩展的学习算法，比如分类、回归等需要 对大量数据集进行
迭代的操作。之前可选的大数据机器学习库 Mahout将会转 到
Spark，并在未来实现。

\paragraph{读入数据}\label{ux8bfbux5165ux6570ux636e}

打开 PySpark 的交互式终端(输入命令``pyspark'')。PySpark 将会自动使用本
地 Spark 配置创建一个 SparkContext，可以通过 sc 变量来访问它。创建第一个
RDD。

\begin{lstlisting}
	pyspark> data = sc.textFile(‘magic04.data’)
\end{lstlisting}

上述命令将下载的数据集 magic04.data 加载到一个 RDD 命名文本。 3.3.2
转化格式并划分训练集定 义一个函数将上面的数据转化为 Spark 分类算法需要的
RDD 格式 (LabeledPoint)。

\begin{lstlisting}
	from pyspark.mllib.regression import LabeledPoint
	def parsedata(line):
	    newline = [a for a in line.split(',')]
	    X = [float(x) for x in newline[:10]]
	    Y = newline[-1]
	    y = 0 if Y=='g' else 1
	    return LabeledPoint(y,X)
\end{lstlisting}

对 data 应用该函数。对转化后的数据 parseddata 进行训练集与测试集的划
分。

\begin{lstlisting}
	pyspark> parseddata = data.map(parsedata)
	## Split the data into training and test sets (70%-training)
	pyspark> (trainingData, testData) = parseddata.randomSplit([0.7, 0.3])
\end{lstlisting}

\paragraph{训练模型}\label{ux8badux7ec3ux6a21ux578b-1}

依然选取 100 棵树在训练集上训练随机森林模型。设置树深为 4，选取
gini指标构建每一棵决策树。

\begin{lstlisting}
	from pyspark.mllib.tree import RandomForest
	model = RandomForest.trainClassifier(trainingData, \
	    numClasses=2, categoricalFeaturesInfo={},numTrees=100,\
	    featureSubsetStrategy="auto",impurity='gini', maxDepth=4)
\end{lstlisting}

\paragraph{检验模型}\label{ux68c0ux9a8cux6a21ux578b}

在测试集上应用上面建立的模型来分类，并与测试集的标准交过作比较，计算误判率，以此来检验模型的
优劣。

\begin{lstlisting}
	predictions = model.predict(testData.map(lambda x: \
	    x.features))
	labelsAndPredictions = testData.map(lambda lp: lp.label \
	    ).zip(predictions)
	cetestErr = labelsAndPredictions.filter(lambda (v, p): \
	    v != p).count() / float(testData.count())
	print('Test Error = ' + str(testErr))
\end{lstlisting}

如果要查看每个子树的具体情况，可以用下面的命令输出：

\begin{lstlisting}
	pyspark> print(model.toDebugString())
\end{lstlisting}

还可以加载 matplotlib 包绘制图像。 计算得出在测试集上的误判率为
17.11\%。

\subsection{结论}\label{ux7ed3ux8bba}

基于 Mahout 的随机森林实现，100 棵树的模型误判率为 12.23\%，1000 棵树
的误判率为 11.96\%；子树的增加使模型准确率略有提升，同时付出了时间的代
价。鉴于两个模型的准确率相差不大，但是计算时间有较大差别，实际中采用适
当的树即可训练出比较满意的模型。

基于 Spark 的随机森林实现，100 棵树的模型误判率为 17.11\%，与基于 Mahout
实现的模型误判率有出
入。这是因为随机森林模型本身就有一定的随机性；另外，本次实验为了测试
Mahout 与 Spark 语句，用 于建立模型的训练集与
测试集是分别划分的，这对于模型的结果也有很大影响。此外，需要注意的
是，Spark 运行的时间明显比在 Hadoop 之上 Mahout 实现
的运行时间短很多，这体现了 Spark 的优势。
