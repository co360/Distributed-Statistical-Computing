\section{岭回归模型}\label{ux5b9eux4f8bux5206ux6790ux5229ux7528mapreduceux8ba1ux7b97ux5cadux56deux5f52ux6a21ux578bux7cfbux6570}

\subsection{准备知识}\label{ux51c6ux5907ux77e5ux8bc6}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Ridge Regression
\item
  R
\item
  Mapreduce
\end{itemize}

\subsection{研究背景}\label{ux7814ux7a76ux80ccux666f}

本案例分析的数据来源于R软件中ISLR包的数据集Hitters，其包含了美国职棒大联盟1986年至1987年
间球员各方面的数据。数据的变量包括球员跑垒数、击打数、失误数、在联盟中的年数等，因变量为球
员的薪资。不难想象，这样的数据是容易存在多重共线性问题的，因此不能使用最小二乘估计系数值，
而需要用其他的估计方法。本文采用的是岭回归方法。


\subsection{数据准备}\label{ux6570ux636eux51c6ux5907}

在数据生成部分，首先加载ISLR包并读取数据；其次对自变量进行标准化处理，另外
注意到数据集中分类型自变量均只有两个水平，因此将它们编码为0和1，作为虚拟变量处理。此外，为
了在最后检验模型的预测效果及筛选$\lambda$值，对数据进行70\%作为训练集、30\%作为测试集的划分，最后将
划分的结果保存，分别命名为train.csv和test.csv。

\begin{lstlisting}
	#! /usr/bin/env Rscript
	#Data generation
	library(ISLR)
	data = Hitters
	data = na.omit(data)
	data$League = as.character(data$League)
	data$League[data$League == "A"] = 0
	data$League[data$League == "N"] = 1
	data$Division = as.character(data$Division)
	data$Division[data$Division == "E"] = 0
	data$Division[data$Division == "W"] = 1
	data$NewLeague = as.character(data$NewLeague)
	data$NewLeague[data$NewLeague == "A"] = 0
	data$NewLeague[data$NewLeague == "N"] = 1
	data$League = as.numeric(data$League)
	data$Division = as.numeric(data$Division)
	data$NewLeague = as.numeric(data$NewLeague)
	igno = -c(14, 15, 19, 20)
	data[, igno] = scale(data[, igno], center = T, scale = T)

	set.seed(2016)
	ind = sample(1:nrow(data), 0.3*nrow(data))
	tr = data[-ind, ]
	te = data[ind, ]
	write.csv(tr, 'train.csv', row.names = F)
	write.csv(te, 'test.csv', row.names = F)
\end{lstlisting}

\subsection{建立模型}\label{ux5efaux7acbux6a21ux578b}

参照岭回归系数的计算公式，比较好的解决方案是先利用并行计算出维度较高、计算量较大的矩阵和，
在最后汇总时再考虑$\lambda$引起的收缩并计算出$\beta$。因此，本文用到了两个\lstinline|mapper|和两个\lstinline|reducer|，分别用于
计算回归分析中的两个维度较高的矩阵$X'X$和$X'Y$。以计算$X'X$的\lstinline|mapper|和\lstinline|reducer|为例，\lstinline|mapper|的输入为（n×p或p×n
维）矩阵，但其计算和输出的是矩阵中每一行分别与所有行相乘的结果，而\lstinline|reducer|则对每一个这样的结果进行按
行求和，得到p个1×p维的向量，并按照这些向量在矩阵计算中相应的顺序进行排序，便可以得到计算的结果。这
样大大减少了每个步骤的计算量，能够有效的提高计算速度。计算$X'Y$矩阵的MapReduce步骤与$X'X$的计算方法类似，这样通过两组矩阵计算的MapReduce框架，将在大数据下难以直接计算的矩阵运算得到解决。

\subsubsection{Mapper部分}\label{mapperux90e8ux5206}

\begin{lstlisting}
	#! /usr/bin/env Rscript
	options(warn = -1)
	sink("/dev/null")
	input = file("stdin", "r")

	read = readLines(input, warn = FALSE)
	temp = strsplit(read[-1], split = ",")
	len = length(temp)
	temp1 = as.numeric(unlist(temp))
	data = matrix(temp1, nrow = len, byrow = T)
	x = t(cbind(1, data[, -(ncol(data)-1)])) #Intercept

	for(i in 1:nrow(x))
	{
	    sink()
	    out = x[i, ] * t(x)
	    cat(out,"\n")
	    sink("/dev/null")
	}

		close(input)
\end{lstlisting}

\subsubsection{Reducer部分}\label{reducerux90e8ux5206}

\begin{lstlisting}
	#! /usr/bin/env Rscript
	options(warn = -1)
	sink("/dev/null")

	input = file("stdin", "r")
	temp = strsplit(readLines(input), split = " ")
	len = length(temp)
	temp1 = lapply(temp, as.numeric)
	temp2 = lapply(temp1, matrix, ncol = len, byrow = F)
	temp3 = lapply(temp2, colSums)

	out = matrix(unlist(temp3), ncol = len)
	write(out, "txx.txt", ncolumns = len)
	close(input)
\end{lstlisting}
在Hadoop集群中运行:

\begin{lstlisting}
	$ hadoop jar /home/dmc/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
	-file /home/dmc/*.py \
	-input xx.csv \
	-output output \
	-mapper "xx_mapper.py" \
	-reducer "xx_reducer.py"
\end{lstlisting}
\begin{lstlisting}
	$ hadoop jar /home/dmc/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
	-file /home/dmc/*.py \
	-input xy.csv \
	-output output \
	-mapper "xy_mapper.py" \
	-reducer "xy_reducer.py"
\end{lstlisting}
\subsubsection{汇总部分}\label{ux6c47ux603bux90e8ux5206}

最后的汇总部分代码直接读取了两个MapReduce的输出结果，由于其维数为p$\times$p维和p$\times$1维，这时已经可以直接对矩阵
进行计算。

在选择最佳的$\lambda$值时，使用的方法是运行简单的循环，找出测试集均方误差最小时对应的$\lambda$值即是最后的
结果。

\begin{lstlisting}
	#! /usr/bin/env Rscript
	txx = read.table('txx.txt', sep = ' ')
	txx = as.matrix(txx)
	txy = read.table('txy.txt', sep = ' ')
	txy = as.matrix(txy, ncol = 1)
	te = read.table('test.csv', sep = ',', header = T)
	lambda = seq(0, 10000, length = 1001)
	tee = numeric()
	for(i in lambda)
	{
	    bhat = solve(txx + diag(nrow(txx)) * i, txy)
	    tey = as.matrix(cbind(1, te[, -(ncol(te) - 1)]))%*%bhat
	    tee = c(tee, mean((tey - te[, ncol(te) - 1])^2))
	}
	lambda = seq(1, lambda[which.min(tee)])
	tee = numeric()
	for(i in lambda)
	{
	    bhat = solve(txx + diag(nrow(txx)) * i, txy)
	    tey = as.matrix(cbind(1, te[, -(ncol(te) - 1)]))%*%bhat
	    tee = c(tee, mean((tey - te[, ncol(te) - 1])^2))
	}
	lambda = which.min(tee)
	print("Lambda:")
	print(lambda)
	print("MSE:")
	print(tee[lambda])
	out = solve(txx + diag(nrow(txx)) * lambda, txy)
	rownames(out) = c("Intercept", names(te)[-19])
	colnames(out) = "Coefficients"
	print(out)
\end{lstlisting}

{\color{red}在回归分析中，影响运算速度的计算步骤一般是最初的矩阵相乘。尤其是在大数据背景下，一般n和p都是非常大的，直接使用软件进行矩阵相乘是非常难的，所占据的空间非常大。所以在大数据背景下，需要拆解矩阵相乘运算，使用并行工具进行并行计算，能有效缓解计算压力。上述岭回归的计算中，就是将矩阵运算拆解成可以并行的步骤，然后使用Hadoop集群计算出矩阵相乘的结果。由于矩阵本身维度很高，但是矩阵相乘之后的维度变成p$\times$p和p$\times$1维，这样的数据维度完全可以使用单机计算。所以总的思路是将数据量很大的基础计算交给Hadoop集群的并行，得到这些基础结果之后，就可以进行统计上的建模分析。}
