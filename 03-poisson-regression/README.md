# 实例分析：对付费搜索广告的泊松回归

## 准备知识

* 泊松回归
* R
* Hadoop Streaming

## 背景介绍


对于一个高度商业化的社会而言,信息的有效传播能够带来可观的商业价值。除了口碑传播以外,企业还
需要其他手段帮助传播产品服务信息,而最常用的手段之一就是广告。广告的有效投放直接决定了企业
的收入、利润、甚至存活。广告媒介的形式有很多,其中最常见的、能够允许消费者主动表达购买意愿
的就是付费搜索广告,它是当下备受关注的搜索引擎营销的核心之一。


付费搜索广告能够更加准确地瞄准目标客户,且价格便宜、门槛低、效果可追踪,这些优点使得它已经被
越来越多的广告客户所接受。然而,要想把它的优点发挥到极致却是一件很不容易的事情,因为能够表达
客户意愿的关键词数量太多,而一个广告商所能维护的关键词数却是非常有限的。那么,如何从上亿个可
能的关键词中找出最出色的部分就成为了付费搜索广告研究的一个核心问题。它要求我们研究不同关键
词的效果(如点击量)和它们的特征(如长度、展现量、排名等)之间的关系。这对指导人们的搜索引擎营
销意义极大。


由此可见,在这个问题中,因变量是点击量。它的取值为非负整数,且具有数值意义,因此我们采用的模型
是适合于计数数据因变量的泊松回归模型。本报告使用某公司付费搜索关键词的相关数据,首先通过随
机抽样将数据进行乱序,然后通过`mapper`函数对数据分块,分别求出泊松回归的系数、p 值等结果,通
过 reducer 函数将上述结果进行平均,得到 MapReduce 并行方法的回归结果,最后再与对数据整体进行
回归的结果作比较,从而研究影响广告关键词点击量的相关因素。


## 数据介绍

报告中的数据来源于国内某培训公司。数据共有 800 个观测值，5个变量，包括一个因变量为点击量，
四个自变量分别为关键词长度，展现量，平均点击价格，平均排名，点击量。其中,关键词长度是指用
户在搜索引擎中输入的内容长短,以字符为单位。当消费者输入一个关键词,搜索引擎便会依据一定规则
把相关网站展现出来,在一定时间段内,被网站展现的次数就是展现量。就一次具体展现而言,一个特定
网站的排名是一个整数,如第一名、第二名等,平均排名是指在一定时间内所发生的所有点击的平均排名
情况。而平均点击价格则是指在一定时间以内所发生的所有点击的平均价格,也常被称为单位点击成本。



## 模型

### 全部数据泊松回归

首先,我们对全部 800 个观测值进行泊松回归。通过调用服务器中的 Rscript编写 R 语言脚本。使用
glm()函数,选择参数中的“family”为泊松回归



	#! /usr/bin/env Rscript
	a = read.csv("poisson.csv", header = T)
	names(a) = c("Y", "X1", "X2", "X3", "X4")
	a[c(1:5), ]
	N = sapply(a, length)
	MU = sapply(a, mean)
	SD = sapply(a, sd)
	MIN = sapply(a, min)
	MED = sapply(a, median)
	MAX = sapply(a, max)
	result = cbind(N, MU, SD, MIN, MED, MAX)
	print(result)
	pos1 = glm(Y ~ X1 + X2 + X3 + X4, family = poisson(), data = a)
	summary(pos1)
	step(pos1)
	pred = predict(pos1, a)
	lam = exp(pred)RME = abs(a$Y - lam) / (1 + lam)
	summary(RME)




得到相应的分析结果如下


	               Coefficients Std. error    P-value
	(Intercept)           1.576     0.393     <0.001
	X1 - 关键词长度      -0.531     0.086     <0.001
	X2 - 展现量           0.002     0.001     <0.001
	X3 - 平均点击价格     0.024     0.003     <0.001
	X4 - 平均排名        -0.109     0.080     0.176


首先注意到,最后一个解释变量 X4 平均排名在 5%的水平下不显著。这就是说,在控制其他变量的前提
下,平均排名的高低和点击量并没有线性关系。出现这种结果的原因很有可能是因为它的信息被别的变
量替代了,比如平均点击价格和展现量。一个关键词的点击量越大,它的平均价格就会越贵,展现量就会
越大,这常常伴随着更高的排名。所以在给定 X2、X3 的前提下,平均排名 X4 不再重要。


对关键词长度来说,它对点击量的影响是负相关的。这说明,越短的关键词,点击量越大;展现量显然是重
要的,且展现量越多,点击量越大;平均点击价格的系数是正的,这说明价格越高的关键词点击量越大,这
些结论与我们的经验常识都是相符合的。


最后,我们用建立的泊松回归模型做预测。通过分析历史数据建立泊松回归模型,获得极大似然估计值，
经过计算得到,该相对误差为 24.8%。这是一个比较不错的预测精度,根据实际经验,该精度能够满足绝
大多数搜索引擎营销关键词研究的需要。


## 基于分块模型的分布式模型计算

在并行计算之前,首先对原始数据进行随机排序,具体的做法是:首先读取原始数据,设置随机数种子,然
后将 1~800 进行不重复地随机排列,并将打乱后的数字作为新数据的行号,从而生成将原始数据随机排
序后的新数据,并保存为 csv 文件。这样做能够保证在接下来的分块计算中,每块的数据都是随机分布
的,且使分块运算结果没有系统上的差异。



	#! /usr/bin/env Rscript
	input = file("stdin", "r")
	poi = readLines(input, warn = F)
	poi = matrix(as.numeric(unlist(strsplit(poi, ","))), ncol = 5, byrow = T)
	poi = data.frame(poi)
	n = dim(poi)[1]
	set.seed(1)
	sam = sample(n)
	poi = poi[sam, ]
	write.csv(poi, "poisson2.csv")
	close(input)



接下来我们对新数据执行 MapReduce 并行计算。该并行过程是通过 mapper函数和 reducer 函数来实
现的。



### Mapper 部分

Mapper 函数的主要功能是对数据进行分块,并对每块数据执行相同的操作,即泊松回归,并显示出模型中
的回归系数、p 值、相对预测误差,最后将结果传递给 reducer 函数。数据共有 800 个观测值,我们用
mapper 函数将随机排序后的数据分成 4 块,每块包含 200 个观测。与全部数据回归的方法相同,使用
glm()函数,选择参数中的“family”为泊松回归,执行出的结果中共有四组回归系数、p 值及相对预测误
差(RME)


	#! /usr/bin/env Rscript
	input = file("stdin", "r")
	test = readLines(input, n=1, warn=F)
	p = length((unlist(strsplit(test, ","))))
	# 求出数据中的变量个数 p
	while(length(data <- readLines(input, n = 200, warn = F)) > 0)
	    # 每 200 行数据为一个分块
	{
	    a = data.frame(matrix(as.numeric(unlist(strsplit(data, ","))), ncol = p, byrow = T))
	    names(a) = c("NUM", "Y", "X1", "X2", "X3", "X4")
	    glm = glm(Y~X1+X2+X3+X4, family = poisson(), data = a)
	    coefficients = glm$coefficients # 回归系数
	    pvalue = summary(glm)$coefficients[, 4] # p 值
	    pred = predict(glm, a)
	    lam = exp(pred)
	    RME = abs(a$Y - lam) / (1+lam)
	    mean = mean(RME)
	        # 相对预测误差
	    cat(coefficients, '\n')
	    cat(pvalue, '\n')
	    cat(mean, '\n')
	}
	close(input)


可以看到,四个分块中的运行结果是有差异的,如第一块中 X2 的系数变为了负值,第三块中 X1 的 p 值
明显偏大导致不显著等。这可能是由于数据量太小,且因变量分布非常不均,大部分取值都为零,仅有小
部分取值为非零的整数,因此会导致数据分区后有一小部分的回归结果出现较大差异。但从整体上来看,
大多数的回归结果都是一致的,且与整体回归结果保持相同。再看四组的相对预测误差,其中第二分区中
的回归预测误差较大,达到了 26%以上,而其余三部分的预测误差都控制在 21%左右。



reducer 函数的主要功能是归约,即对映射后的结果进行合并整理。在本案例中,将上述 mapper 函数的
运行结果通过管道传递给 reducer 函数,并分别对不同数据块中的回归系数、p 值、相对预测误差求均
值,即得到最终的结果。传递给 reducer 函数的结果共有 12 行,每 3 行是一个数据块的回归结果。其
中,第 1 行、第 4 行、第 7 行和第 10 行数据是回归系数结果,我们需要对其加和再平均;同理,第 2、
5、8、11 行是 p 值,第 3、6、9、12 行是预测误差。针对这种情况,我们考虑使用对行数除以 3 求余
数的方法进行分类,从而分别对系数、p 值、预测误差求得平均值。最终的执行结果如下表所示。



    #! /usr/bin/env Rscript
	input = file("stdin", "r")
	i = 0
	coefficients = rep(0,5)
	pvalue = rep(0,5)
	mean = 0
	while(length(mapresult <- readLines(input, n = 1, warn = F)) > 0)
	{
	    i = i+1
	    fields = strsplit(mapresult, ' ')
	    if (i%%3 == 1) {
            # 对 1、4、7、10 行的系数求和
	        coefficients = coefficients + as.numeric(fields[[1]])
	    }
	    else if (i%%3 == 2) {
	        pvalue = pvalue + as.numeric(fields[[1]])
	            # 对 2、5、8、11 行的 p 值求和
	    }
	    else if (i%%3 == 0) {
	        mean = mean + as.numeric(fields[[1]])
              # 对 3、6、9、12 行的误差求和
	    }
	}
	coefficients = coefficients/(i/3)
	pvalue = pvalue/(i/3)
	mean = mean/(i/3)
	cat('coefficients =', coefficients, '\n')
	cat('pvalue =', pvalue, '\n')
	cat('RME =', mean, '\n')
	close(input)



### 与全数据模型比较

将上述结果与表 2 中结果进行对比可以发现,用全部数据进行泊松回归和用并行方法分块进行回归的截
距项和各回归项系数的结果都是非常接近的。对比 p 值后可以看到,并行结果中除了 X4 以外,X1 在
5%的显著性水平下也无法通过检验。我们再看一下表 3 就会发现,在四个数据块中,有三个部分的变量
X1 的 p 值都是小于 0.001 的,仅在第三个分区中,变量 X1 的 p 值高达0.562,这就使得其平均值被拉
高,导致表 4 中关键词长度变量不显著的出现。而其他各变量是否显著的判断结果都与表 2 完全相同。
最后再看 RME,并行结果的相对预测误差是 22.5%,要稍小于全回归中的预测误差 24.8%。这是很容易理
解的,因为对 800 个观测值做总体的回归和对 200个观测值做部分回归,肯定是数据量越少产生的偏差
越小。在并行计算中,每个数据分块拟合的回归结果都会更接近这个区域中的数据特性,因此相对预测误
差要更小是很合理的结果。



## 结论

报告通过付费搜索广告的案例,对泊松回归及其 MapReduce 并行计算做了简要的概述,并将并行方法的
回归结果与对数据整体进行回归的结果做了比较,研究了关键词点击量大小同关键词长度、平均点击价
格、平均排名及展现量之间的关系,并对结果做了详细展示。


其中,关键词长度同点击量显著地负相关,而展现量和平均点击价格同点击量显著地正相关。在控制其他
变量的前提下,平均排名的高低则与点击量并没有显著关系。同时,我们也对所建立模型的预测精度予以
评估,效果良好。在并行计算中,我们对随机排序后的新数据通过 mapper 函数和 reducer 函数执行了
MapReduce 的并行实现。在本案例中,mapper 函数的主要功能是对数据进行分块,并对每块数据拟合泊
松回归,将一系列结果传递给 reducer 函数; reducer 函数则对接收的数据进行归约及整合,分别对不
同数据块中的回归系数、p 值、相对预测误差求均值,即得到最终的结果。这种用管道传递的并行方法
较为基础和原始,同时,由于数据量的不足和因变量的分布原因,造成了数据分块后的运行结果与总体回
归结果出现了部分差异。但总的来说,两种方法的结果大致相同。在数据量较大的情况下,采用并行计算
方法还是非常有必要和可行的。

（感谢中央财经大学郑巧筠提供素材和案例。）
