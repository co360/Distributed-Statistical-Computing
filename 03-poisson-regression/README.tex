\section{泊松回归模型：付费搜索广告分析}\label{ux5b9eux4f8bux5206ux6790ux5bf9ux4ed8ux8d39ux641cux7d22ux5e7fux544aux7684ux6ccaux677eux56deux5f52}

\subsection{准备知识}\label{ux51c6ux5907ux77e5ux8bc6}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  泊松回归
\item
  R
\item
  Hadoop Streaming
\end{itemize}

\subsection{背景介绍}\label{ux80ccux666fux4ecbux7ecd}

对于一个高度商业化的社会而言，信息的有效传播能够带来可观的商业价值。除了口碑传播以外，企业
还需要其他手段帮助传播产品服务信息，而最常用的手段之一就是广告。广告的有效投放直接决定了企
业的收入、利润、甚至存活。广告媒介的形式有很多,其中最常见的、能够允许消费者主动表达购买意愿
的就是付费搜索广告，它是当下备受关注的搜索引擎营销的核心之一。

付费搜索广告能够更加准确地瞄准目标客户，且价格便宜、门槛低、效果可追踪，这些优点使得它已经
被越来越多的广告客户所接受。然而,要想把它的优点发挥到极致却是一件很不容易的事情，因为能够表
达客户意愿的关键词数量太多，而一个广告商所能维护的关键词数却是非常有限的。那么，如何从上亿
个可能的关键词中找出最出色的部分就成为了付费搜索广告研究的一个核心问题。它要求我们研究不同
关键词的效果(如点击量)和它们的特征(如长度、展现量、排名等)之间的关系。这对指导人们的搜索引
擎营销意义极大。

由此可见，在这个问题中，因变量是点击量。它的取值为非负整数，且具有数值意义，因此我们采用的
模型是适合于计数数据因变量的泊松回归模型。本报告使用某公司付费搜索关键词的相关数据，首先通
过随机抽样将数据进行乱序，然后通过\lstinline!mapper!函数对数据分块，分别求出泊松回归的系
数、\lstinline!p! 值等结果，通过\lstinline!reducer! 函数将上述结果进行平均，得
到 MapReduce并行方法的回归结果，最后再与对数据整体进行回归的结果作比较，从而研究影响广告关
键词点击量的相关因素。

\subsection{数据介绍}\label{ux6570ux636eux4ecbux7ecd}

报告中的数据来源于国内某培训公司。数据共有 800个观测值，5个变量，包括一个因变量为点击量，四
个自变量分别为关键词长度、展现量、平均点击价格、平均排名、点击量。其中，关键词长度是指用户
在搜索引擎中输入的内容长短,以字符为单位。当消费者输入一个关键词，搜索引擎便会依据一定规则把
相关网站展现出来，在一定时间段内，被网站展现的次数就是展现量。就一次具体展现而言，一个特定
网站的排名是一个整数，如第一名、第二名等，平均排名是指在一定时间内所发生的所有点击的平均排
名情况。而平均点击价格则是指在一定时间以内所发生的所有点击的平均价格，也常被称为单位点击成
本。

\subsection{模型}\label{ux6a21ux578b}

\subsubsection{全部数据泊松回归}\label{ux5168ux90e8ux6570ux636eux6ccaux677eux56deux5f52}

首先，我们对全部 800 个观测值进行泊松回归。通过调用服务器中的 Rscript编写
R 语言脚本。使用 \lstinline!glm()!函数，选择参数中的``\lstinline!family!''为泊松回归

\begin{lstlisting}
	#! /usr/bin/env Rscript
	a = read.csv("poisson.csv", header = T)
	names(a) = c("Y", "X1", "X2", "X3", "X4")
	N = sapply(a, length)
	MU = sapply(a, mean)
	SD = sapply(a, sd)
	MIN = sapply(a, min)
	MED = sapply(a, median)
	MAX = sapply(a, max)
	result = cbind(N, MU, SD, MIN, MED, MAX)
	print(result)
	pos1 = glm(Y ~ X1 + X2 + X3 + X4, family = poisson(), data = a)
	summary(pos1)
	step(pos1)
	pred = predict(pos1, a)
	lam = exp(pred)
	RME = abs(a$Y - lam) / (1 + lam)
	summary(RME)
\end{lstlisting}

得到相应的分析结果如下

\begin{lstlisting}
	               Coefficients Std. error    P-value
	(Intercept)           1.576     0.393     <0.001
	X1 - 关键词长度      -0.531     0.086     <0.001
	X2 - 展现量           0.002     0.001     <0.001
	X3 - 平均点击价格     0.024     0.003     <0.001
	X4 - 平均排名        -0.109     0.080     0.176
\end{lstlisting}

首先注意到，最后一个解释变量 X4 平均排名在5\%的水平下不显著。这就是说，在控制其他变量的前提
下，平均排名的高低和点击量并没有显著线性关系。出现这种结果的原因很有可能是它的信息被别的变
量替代了，比如平均点击价格和展现量。一个关键词的点击量越大，它的平均价格就会越高，展现量就
会越大，这常常伴随着更高的排名。所以在给定 X2、X3 的前提下，平均排名 X4不再重要。

对关键词长度来说，它对点击量的影响是负相关的，这说明，越短的关键词，点击量越大；展现量显然
是重要的变量，且展现量越多，点击量越大；平均点击价格的系数是正的，这说明价格越高的关键词点
击量越大，这些结论与我们的经验常识都是相符合的。

最后，我们用建立的泊松回归模型做预测。通过分析历史数据建立泊松回归模型，获得极大似然估计值，
经过计算得到，该相对误差为24.8\%。这是一个比较不错的预测精度，根据实际经验，该精度能够满足
绝大多数搜索引擎营销关键词研究的需要。

\subsection{基于分块模型的分布式模型计算}\label{ux57faux4e8eux5206ux5757ux6a21ux578bux7684ux5206ux5e03ux5f0fux6a21ux578bux8ba1ux7b97}

在并行计算之前，首先对原始数据进行随机排序。具体的做法是：首先读取原始数据，设置随机数种子，
然后将 1\textasciitilde{}800进行不重复地随机排列，并将打乱后的数字作为新数据的行号，从而生
成将原始数据随机排序后的新数据，并保存为 csv文件。这样做能够保证在接下来的分块计算中，每块
的数据都是随机分布的，且使分块运算结果没有系统上的差异。

\begin{lstlisting}
	#! /usr/bin/env Rscript
	input = file("stdin", "r")
	poi = readLines(input, warn = F)
	poi = matrix(as.numeric(unlist(strsplit(poi, ","))), ncol = 5, byrow = T)
	poi = data.frame(poi)
	n = dim(poi)[1]
	set.seed(1)
	sam = sample(n)
	poi = poi[sam, ]
	write.csv(poi, "poisson2.csv")
	close(input)
\end{lstlisting}

接下来我们对新数据执行 MapReduce 并行计算。该并行过程是通过 \lstinline!mapper!函数和
\lstinline!reducer! 函数来实 现的。

\subsubsection{Mapper 部分}\label{mapper-ux90e8ux5206}

\lstinline!Mapper! 函数的主要功能是对数据进行分块，并对每块数据执行相同的操作，即泊松回归，
并显示出模型中的回归系数、\lstinline!p! 值、相对预测误差，最后将结果传递
给 \lstinline!reducer! 函数。数据共有800 个观测值,我们用 \lstinline!mapper! 函数将随机排序
后的数据分成 4 块,每块包含 200个观测。与全部数据回归的方法相同,使用\lstinline!glm()!函数,选
择参数中的``\lstinline!family!''为泊松回归,执行出的结果中共有四组回归系数、\lstinline!p! 值
及相对预测误 差(RME)。

\begin{lstlisting}
	#! /usr/bin/env Rscript
	input = file("stdin", "r")
	test = readLines(input, n=1, warn=F)
	p = length((unlist(strsplit(test, ","))))
	# 求出数据中的变量个数 p
	while(length(data <- readLines(input, n = 200, warn = F)) > 0)
	    # 每 200 行数据为一个分块
	{
	    a = data.frame(matrix(as.numeric(unlist(strsplit(data, ","))), ncol = p, byrow = T))
	    names(a) = c("NUM", "Y", "X1", "X2", "X3", "X4")
	    glm = glm(Y~X1+X2+X3+X4, family = poisson(), data = a)
	    coefficients = glm$coefficients # 回归系数
	    pvalue = summary(glm)$coefficients[, 4] # p 值
	    pred = predict(glm, a)
	    lam = exp(pred)
	    RME = abs(a$Y - lam) / (1+lam)
	    mean = mean(RME)
	    # 相对预测误差
	    cat(coefficients, '\n')
	    cat(pvalue, '\n')
	    cat(mean, '\n')
	}
	close(input)
\end{lstlisting}

可以看到，四个分块中的运行结果是有差异的，如第一块中 X2的系数变为了负值,第三块中 X1 的 p 值
明显偏大导致不显著等。这可能是由于数据量太小，且因变量分布非常不均，大部分取值都为零，仅有
小部分取值为非零的整数，因此会导致数据分区后有一小部分的回归结果出现较大差异。但从整体上来
看，大多数的回归结果都是一致的，且与整体回归结果保持相同。再看四组的相对预测误差，其中第二
分区中的回归预测误差较大，达到了 26\%以上，而其余三部分的预测误差都控制在21\%左右。

\lstinline!Reducer! 函数的主要功能是归约，即对映射后的结果进行合并整理。在本案例中，将上
述\lstinline!mapper! 函数的 运行结果通过管道传递给 \lstinline!reducer! 函数，并分别对不同数
据块中的回归系数、p 值、相对预测误差求均值，即得到最终的结果。传递给 \lstinline!reducer! 函
数的结果共有 12 行，每 3行是一个数据块的回归结果。其 中，第 1 行、第 4 行、第 7 行和第 10行
数据是回归系数结果，我们需要对其加和再平均；同理，第 2、 5、8、11 行是 p值，第 3、6、9、12
行是预测误差。针对这种情况，我们考虑使用对行数除以 3求余 数的方法进行分类，从而分别对系
数、p值、预测误差求得平均值。最终的执行结果如下表所示。

\begin{lstlisting}
	#! /usr/bin/env Rscript
	input = file("stdin", "r")
	i = 0
	coefficients = rep(0,5)
	pvalue = rep(0,5)
	mean = 0
	while(length(mapresult <- readLines(input, n = 1, warn = F)) > 0)
	{
	    i = i+1
	    fields = strsplit(mapresult, ' ')
	    if (i%%3 == 1) {
	        # 对 1、4、7、10 行的系数求和
	        coefficients = coefficients + as.numeric(fields[[1]])
	    }
	    else if (i%%3 == 2) {
	        pvalue = pvalue + as.numeric(fields[[1]])
	            # 对 2、5、8、11 行的 p 值求和
	    }
	    else if (i%%3 == 0) {
	        mean = mean + as.numeric(fields[[1]])
	          # 对 3、6、9、12 行的误差求和
	    }
	}
	coefficients = coefficients/(i/3)
	pvalue = pvalue/(i/3)
	mean = mean/(i/3)
	cat('coefficients =', coefficients, '\n')
	cat('pvalue =', pvalue, '\n')
	cat('RME =', mean, '\n')
	close(input)
\end{lstlisting}
模拟 Hadoop 模式调试:

\begin{lstlisting}
	$ cat poisson.csv | python mapper.py | python reducer.py
\end{lstlisting}
如果在Hadoop集群运行:

\begin{lstlisting}
	$ hadoop jar /home/dmc/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar \
	-file /home/dmc/*.py \
	-input poisson.csv \
	-output output \
	-mapper "mapper.py" \
	-reducer "reducer.py"
\end{lstlisting}


\subsubsection{与全数据模型比较}\label{ux4e0eux5168ux6570ux636eux6a21ux578bux6bd4ux8f83}

将上述结果与表 2中结果进行对比可以发现，用全部数据进行泊松回归和用并行方法分块进行回归的截
距项和各回归项系数的结果都是非常接近的。对比 p值后可以看到，并行结果中除了 X4 以
外，X1 在5\%的显著性水平下也无法通过检验。我们再看一下表 3就会发现，在四个数据块中，有三个
部分的变量 X1 的 p 值都是小于 0.001的，仅在第三个分区中，变量 X1 的 p 值高达0.562，这就使得
其平均值被拉高，导致表 4中关键词长度变量不显著的出现。而其他各变量是否显著的判断结果都与
表 2完全相同。 最后再看 RME，并行结果的相对预测误差是22.5\%，要稍小于全回归中的预测误
差 24.8\%。这是很容易理解的，因为对 800个观测值做总体的回归和对200个观测值做部分回归，肯定
是数据量越少产生的偏差越小。在并行计算中，每个数据分块拟合的回归结果都会更接近这个区域中的
数据特性，因此相对预测误差要更小是很合理的结果。

\subsection{结论}\label{ux7ed3ux8bba}

通过付费搜索广告的案例，对泊松回归及其 MapReduce并行计算做了简要的概述，并将并行方法的回归
结果与对数据整体进行回归的结果做了比较，研究了关键词点击量大小同关键词长度、平均点击价格、
平均排名及展现量之间的关系，并对结果做了详细展示。

其中，关键词长度同点击量显著地负相关，而展现量和平均点击价格同点击量显著地正相关。在控制其
他变量的前提下，平均排名的高低则与点击量并没有显著关系。同时，我们也对所建立模型的预测精度
予以评估，效果良好。在并行计算中，我们对随机排序后的新数据通过 \lstinline!mapper! 函数
和\lstinline!reducer! 函数执行了 MapReduce 的并行实现。在本案例中，\lstinline!mapper! 函数
的主要功能是对数据进行分块，并对每块数据拟合泊松回归，将一系列结果传递
给 \lstinline!reducer! 函数； \lstinline!reducer! 函数则对接收的数据进行归约及整合，分别对
不同数据块中的回归系数、p值、相对预测误差求均值，即得到最终的结果。这种用管道传递的并行方法
较为基础和原始，同时，由于数据量的不足和因变量的分布原因，造成了数据分块后的运行结果与总体
回归结果出现了部分差异。但总的来说，两种方法的结果大致相同。在数据量较大的情况下，采用并行
计算方法还是非常有必要和可行的。
