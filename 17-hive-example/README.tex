\section{Hive实例：FoodMart案例}\label{ux5b9eux4f8bux5206ux6790foodmartux6570ux636eux96c6ux5728hiveux5e73ux53f0ux7684ux4f7fux7528ux6848ux4f8b}

\subsection{准备知识}\label{ux51c6ux5907ux77e5ux8bc6}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Hive
\end{itemize}

\subsection{数据准备}\label{ux6570ux636eux51c6ux5907}

FoodMart数据库为某家大型的食品连锁店的经营业务所产生的数据，该数据涉及到了公司经营的各个方面，包括产品、库存、人事、客户和销售等。该数据库中的表包括顾客的基本信息表、货币信息表、公司部门表、职员表、消费表、地区表等。FoodMart数据库经常用于多维分析的测试数据集，同数据库部分的学习，我们选取其中一个数据库子集：sales\_fact\_1997、customer、product、product\_class、time\_by\_day、store、promotion7个表导入Hive中进行测试。
在进行测试之前，我们需要在原有数据库中将所需要的数据表导出，此处，我们以文本形式为例进行。各表的维度如表~\ref{tab:Footmart-dimension}所示：


\begin{table}[!hbp]
	\centering
	\caption{FootMart示例数据各表维度}
	\label{tab:Footmart-dimension}
	\begin{tabular}{lll}
\toprule
	表名  &行数&列数\\
\midrule
\texttt{customer} &10,281 &29\\
\texttt{product} &1,560 &15\\
\texttt{product\_class} &110 &5\\
\texttt{store} &25 &25\\
\texttt{promotion} &1,864 &7\\
\texttt{sales\_fact\_1977} &210429 &8\\
\texttt{time\_by\_day} &730 &10\\
\bottomrule
	\end{tabular}

\end{table}

\subsection{数据迁移与导入}\label{ux6570ux636eux8fc1ux79fbux4e0eux5bfcux5165}

\subsubsection{创建数据库}\label{ux521bux5efaux6570ux636eux5e93}

创建名为``FoodMart''的数据库并使用：

\begin{lstlisting}
	Hive> CREATE DATABASE IF NOT EXISTS FoodMart;
	Hive> USE FoodMart;
\end{lstlisting}

\subsubsection{创建表格}\label{ux521bux5efaux8868ux683c}

store表维度最小，在此以创建store表为例，首先在FoodMart数据库下创建名为``store''的表，随后将本地数据LOAD至HIVE端即可：
创建表格：

\begin{lstlisting}
	Hive> CREATE TABLE IF NOT EXISTS store (
	store_id INT, store_type STRING,region_id INT,store_name STRING, store_number INT, store_street_address STRING, store_city STRING,store_state STRING,   store_postal_code STRING,store_country STRING, store_manager STRING, store_phone STRING, store_fax STRING,first_opened_date STRING, last_remodel_date STRING, lease_sqft STRING,    store_sqft STRING,  grocery_sqft STRING, frozen_sqft STRING,meat_sqft STRING, coffee_bar STRING, video_store STRING, salad_bar STRING,  prepared_food STRING, florist STRING)
	ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
\end{lstlisting}

\subsubsection{导入数据}\label{ux5bfcux5165ux6570ux636e}

\begin{lstlisting}
	Hive> LOAD DATA LOCAL INPATH '/home/dmc/FoodMart_Data/store.txt' OVERWRITE INTO TABLE store;
\end{lstlisting}

使用count(1)函数查看数据维度:

\begin{lstlisting}
	Hive> select count(1) from store;
\end{lstlisting}

由于我们所使用的数据较小，在此没有使用PARTITION对数据进行分区操作；当有数据量较大的数据进行迁移时，可使用字段中可分区的字段对数据进行分区存储，真正达到分布式数据存储效果。
通过show tables语句查看现有数据库下的表格：

\begin{lstlisting}
	Hive> show tables;
\end{lstlisting}

\subsection{数据查询示例}\label{ux6570ux636eux67e5ux8be2ux793aux4f8b}

简单查询，如查询编号为1的用户在customer表中的所有信息：

\begin{lstlisting}
	Hive> select * from customer where customer_id=1;
\end{lstlisting}

连接查询，查询销售额最高的top3的用户是谁，基本的思路是先查询sales\_fact\_1997中排序前3的customer\_id，再使用id与customer做连接查询出其他信息如姓名即可。
单独对销量表查询排序，代码如下：

\begin{lstlisting}
	Hive> select customer_id, sum(store_cost)
	as cost_total from
	sales_fact_1997 group by customer_id sort by cost_total
	DESC limit 3;
\end{lstlisting}

以查询用户的姓名为例，完整的SQL语句可参考：

\begin{lstlisting}
	Hive> select b.lname,b.fname,a.cost_total from
	(select customer_id, sum(store_cost) as cost_total from
	sales_fact_1997 group by customer_id sort by cost_total
	DESC limit 3 ) a
	left outer join
	(select customer_id, lname,fname from customer ) b
	on a.customer_id=b.customer_id;
\end{lstlisting}

返回的结果即可看到用户的lname,fname和销售额组成的3×3的数据表。

\subsubsection{数据导出操作}\label{ux6570ux636eux5bfcux51faux64cdux4f5c}

在日常的数据工作中，我们并不满足于仅在服务器端对数据进行类别的统计，很多时候，我们需要将数据下载到本地进行进一步的分析与操作。如何将Hive数据导出将是这一节介绍的内容。
整体来说，实际工作中导出Hive平台的数据大致分为两个步骤，一为直接在Hive平台环境下将数据导出到本地文件系统、导出到HDFS中；二为切换到服务器环境，即Linux工作环境，使用Shell命令对数据进行服务器端的导出。
首先我们介绍直接在Hive平台上如何进行数据的导出。以简单查询为例，现在我们想将所有家庭拥有孩子数大于2的用户的customer信息表中的信息导出进行进一步的分析工作，若直接导出到本地文件系统：

\begin{lstlisting}
	Hive> insert overwrite local directory
	'/home/dmc/customer_1'
	select * from customer where total_children> 2;
\end{lstlisting}

与数据导入不同，这里不再是\texttt{insert into}语句。通过\texttt{insert overwrite local
directory}将Hive中的表导出到本地文件系统的目录下也是通过MapReduce完成的，运行完语句后，目标文件夹下将产生名为类似000000\_0的文件。
将数据导出到HDFS与导出到本地文件系统类似，仅需在directory前省略local即可，这时数据存放的路径就改变了。
此外，在Linux环境下，还可通过Shell命令行将数据导出：

\begin{lstlisting}
	$ hive -e "select * from foodmart.customer where total_children> 2" >> local/customer_2.txt
\end{lstlisting}

如果是事先写好的SQL脚本，还可通过-f调用sql文件，如若将上述select操作写入文件customer\_U.sql，则数据导出操作为：

\begin{lstlisting}
	$ hive -f customer_U.sql >> customer_3.txt
\end{lstlisting}

按照上面的示例将数据导出到本地文件系统后，即可在Linux端使用sz操作将数据从服务器本地文件下载到个人Windows电脑（注：使用sz命令，Linux需要安装\texttt{lrzsz}），或者使用诸如WinScp等图形化SFTP客户端。
