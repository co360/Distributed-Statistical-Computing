{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark 与机器学习\n",
    "\n",
    "\n",
    "李丰\n",
    "\n",
    "feng.li@cufe.edu.cn\n",
    "\n",
    "中央财经大学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Spark 机器学习辅助工具\n",
    "\n",
    "- 模型选择工具\n",
    "- 交叉验证模块\n",
    "- 训练集测试集拆分\n",
    "- [模型评估工具](https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html)：Precision，Recall， ROC，F-measure\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Spark MLlib 内置的机器学习模型\n",
    "\n",
    "- 文本特征提取： TF-IDF，Word2Vec, n-gram\n",
    "- 分类模型：朴素贝叶斯，逻辑回归，随机森林，决策树\n",
    "- 聚类：K-Means，LDA，Mixtures\n",
    "- 降维/变量选择：PCA，SVD, LASSO\n",
    "- 模式识别\n",
    "- 流数据处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### [Spark 优化工具](https://spark.apache.org/docs/latest/mllib-optimization.html)\n",
    "\n",
    "- 梯度下降、随机梯度下降\n",
    "- BFGS、LBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 准备工作\n",
    "\n",
    "我们首先加载Python的pypark模块并且注册一个Spark App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/lib/spark-current\")\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"Spark Machine Learning App\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Load data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"kmeans_data.txt\")\n",
    "\n",
    "# Train a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.9997530305375207\n",
      "Cluster Centers: \n",
      "[ 0.1  0.1  0.1]\n",
      "[ 9.1  9.1  9.1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(dataset)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark 中实现逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "training = spark.read.format(\"libsvm\").load(\"libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=SparseVector(692, {127: 51.0, 128: 159.0, 129: 253.0, 130: 159.0, 131: 50.0, 154: 48.0, 155: 238.0, 156: 252.0, 157: 252.0, 158: 252.0, 159: 237.0, 181: 54.0, 182: 227.0, 183: 253.0, 184: 252.0, 185: 239.0, 186: 233.0, 187: 252.0, 188: 57.0, 189: 6.0, 207: 10.0, 208: 60.0, 209: 224.0, 210: 252.0, 211: 253.0, 212: 252.0, 213: 202.0, 214: 84.0, 215: 252.0, 216: 253.0, 217: 122.0, 235: 163.0, 236: 252.0, 237: 252.0, 238: 252.0, 239: 253.0, 240: 252.0, 241: 252.0, 242: 96.0, 243: 189.0, 244: 253.0, 245: 167.0, 262: 51.0, 263: 238.0, 264: 253.0, 265: 253.0, 266: 190.0, 267: 114.0, 268: 253.0, 269: 228.0, 270: 47.0, 271: 79.0, 272: 255.0, 273: 168.0, 289: 48.0, 290: 238.0, 291: 252.0, 292: 252.0, 293: 179.0, 294: 12.0, 295: 75.0, 296: 121.0, 297: 21.0, 300: 253.0, 301: 243.0, 302: 50.0, 316: 38.0, 317: 165.0, 318: 253.0, 319: 233.0, 320: 208.0, 321: 84.0, 328: 253.0, 329: 252.0, 330: 165.0, 343: 7.0, 344: 178.0, 345: 252.0, 346: 240.0, 347: 71.0, 348: 19.0, 349: 28.0, 356: 253.0, 357: 252.0, 358: 195.0, 371: 57.0, 372: 252.0, 373: 252.0, 374: 63.0, 384: 253.0, 385: 252.0, 386: 195.0, 399: 198.0, 400: 253.0, 401: 190.0, 412: 255.0, 413: 253.0, 414: 196.0, 426: 76.0, 427: 246.0, 428: 252.0, 429: 112.0, 440: 253.0, 441: 252.0, 442: 148.0, 454: 85.0, 455: 252.0, 456: 230.0, 457: 25.0, 466: 7.0, 467: 135.0, 468: 253.0, 469: 186.0, 470: 12.0, 482: 85.0, 483: 252.0, 484: 223.0, 493: 7.0, 494: 131.0, 495: 252.0, 496: 225.0, 497: 71.0, 510: 85.0, 511: 252.0, 512: 145.0, 520: 48.0, 521: 165.0, 522: 252.0, 523: 173.0, 538: 86.0, 539: 253.0, 540: 225.0, 547: 114.0, 548: 238.0, 549: 253.0, 550: 162.0, 566: 85.0, 567: 252.0, 568: 249.0, 569: 146.0, 570: 48.0, 571: 29.0, 572: 85.0, 573: 178.0, 574: 225.0, 575: 253.0, 576: 223.0, 577: 167.0, 578: 56.0, 594: 85.0, 595: 252.0, 596: 252.0, 597: 252.0, 598: 229.0, 599: 215.0, 600: 252.0, 601: 252.0, 602: 252.0, 603: 196.0, 604: 130.0, 622: 28.0, 623: 199.0, 624: 252.0, 625: 252.0, 626: 253.0, 627: 252.0, 628: 252.0, 629: 233.0, 630: 145.0, 651: 25.0, 652: 128.0, 653: 252.0, 654: 253.0, 655: 252.0, 656: 141.0, 657: 37.0})),\n",
       " Row(label=1.0, features=SparseVector(692, {158: 124.0, 159: 253.0, 160: 255.0, 161: 63.0, 185: 96.0, 186: 244.0, 187: 251.0, 188: 253.0, 189: 62.0, 213: 127.0, 214: 251.0, 215: 251.0, 216: 253.0, 217: 62.0, 240: 68.0, 241: 236.0, 242: 251.0, 243: 211.0, 244: 31.0, 245: 8.0, 267: 60.0, 268: 228.0, 269: 251.0, 270: 251.0, 271: 94.0, 295: 155.0, 296: 253.0, 297: 253.0, 298: 189.0, 322: 20.0, 323: 253.0, 324: 251.0, 325: 235.0, 326: 66.0, 349: 32.0, 350: 205.0, 351: 253.0, 352: 251.0, 353: 126.0, 377: 104.0, 378: 251.0, 379: 253.0, 380: 184.0, 381: 15.0, 404: 80.0, 405: 240.0, 406: 251.0, 407: 193.0, 408: 23.0, 431: 32.0, 432: 253.0, 433: 253.0, 434: 253.0, 435: 159.0, 459: 151.0, 460: 251.0, 461: 251.0, 462: 251.0, 463: 39.0, 486: 48.0, 487: 221.0, 488: 251.0, 489: 251.0, 490: 172.0, 514: 234.0, 515: 251.0, 516: 251.0, 517: 196.0, 518: 12.0, 542: 253.0, 543: 251.0, 544: 251.0, 545: 89.0, 569: 159.0, 570: 255.0, 571: 253.0, 572: 253.0, 573: 31.0, 596: 48.0, 597: 228.0, 598: 253.0, 599: 247.0, 600: 140.0, 601: 8.0, 624: 64.0, 625: 251.0, 626: 253.0, 627: 220.0, 652: 64.0, 653: 251.0, 654: 253.0, 655: 220.0, 680: 24.0, 681: 193.0, 682: 253.0, 683: 220.0})),\n",
       " Row(label=1.0, features=SparseVector(692, {124: 145.0, 125: 255.0, 126: 211.0, 127: 31.0, 151: 32.0, 152: 237.0, 153: 253.0, 154: 252.0, 155: 71.0, 179: 11.0, 180: 175.0, 181: 253.0, 182: 252.0, 183: 71.0, 208: 144.0, 209: 253.0, 210: 252.0, 211: 71.0, 235: 16.0, 236: 191.0, 237: 253.0, 238: 252.0, 239: 71.0, 263: 26.0, 264: 221.0, 265: 253.0, 266: 252.0, 267: 124.0, 268: 31.0, 292: 125.0, 293: 253.0, 294: 252.0, 295: 252.0, 296: 108.0, 321: 253.0, 322: 252.0, 323: 252.0, 324: 108.0, 349: 255.0, 350: 253.0, 351: 253.0, 352: 108.0, 377: 253.0, 378: 252.0, 379: 252.0, 380: 108.0, 405: 253.0, 406: 252.0, 407: 252.0, 408: 108.0, 433: 253.0, 434: 252.0, 435: 252.0, 436: 108.0, 461: 255.0, 462: 253.0, 463: 253.0, 464: 170.0, 489: 253.0, 490: 252.0, 491: 252.0, 492: 252.0, 493: 42.0, 517: 149.0, 518: 252.0, 519: 252.0, 520: 252.0, 521: 144.0, 545: 109.0, 546: 252.0, 547: 252.0, 548: 252.0, 549: 144.0, 574: 218.0, 575: 253.0, 576: 253.0, 577: 255.0, 578: 35.0, 602: 175.0, 603: 252.0, 604: 252.0, 605: 253.0, 606: 35.0, 630: 73.0, 631: 252.0, 632: 252.0, 633: 253.0, 634: 35.0, 658: 31.0, 659: 211.0, 660: 252.0, 661: 253.0, 662: 35.0}))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 模型设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, \n",
    "                        regParam=0.3,  # regularization parameter\n",
    "                        elasticNetParam=0.8) # ElasticNet mixing parameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22456315961250325"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {244: -0.0001, 263: -0.0001, 272: -0.0002, 300: -0.0002, 301: -0.0, 328: -0.0001, 350: 0.0, 351: 0.0, 378: 0.0004, 379: 0.0001, 405: 0.0001, 406: 0.0006, 407: 0.0003, 428: -0.0001, 433: 0.0004, 434: 0.0006, 455: -0.0001, 456: -0.0002, 461: 0.0003, 462: 0.0006, 483: -0.0002, 484: -0.0001, 489: 0.0003, 490: 0.0003, 496: -0.0001, 511: -0.0004, 512: -0.0003, 517: 0.0003, 539: -0.0002, 540: -0.0015, 568: -0.0002})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 模型迭代细节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "Iter-1: 0.6833149135741672\n",
      "Iter-2: 0.6662875751473734\n",
      "Iter-3: 0.6217068546034618\n",
      "Iter-4: 0.6127265245887887\n",
      "Iter-5: 0.6060347986802873\n",
      "Iter-6: 0.6031750687571562\n",
      "Iter-7: 0.5969621534836274\n",
      "Iter-8: 0.5940743031983118\n",
      "Iter-9: 0.5906089243339022\n",
      "Iter-10: 0.5894724576491042\n",
      "Iter-11: 0.5882187775729587\n"
     ]
    }
   ],
   "source": [
    "objectiveHistory = lrModel.summary.objectiveHistory\n",
    "\n",
    "iIter = 0\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    iIter += 1\n",
    "    print(\"Iter-\"+ str(iIter) + \": \" + str(objective))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark 中流数据的线性回归\n",
    "\n",
    "- 数据是以数据流的形式进入模型\n",
    "- 在线模型会随着数据的增加而调整模型参数（本质上为贝叶斯更新) \n",
    "$$p(\\theta|y_{1:[T+1]}) \\propto p(y_{T+1}| \\theta)p(\\theta | y_{1:T})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 流数据的回归模型实现\n",
    "\n",
    "- `mllib` 提供了分布式的随机梯度下降算法\n",
    "- example: `streaming_linear_regression.py`\n",
    "\n",
    "- 运行方式: `python3 streaming_linear_regression.py <trainingDir> <testDir>`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 一个在线模型的Spark三部曲\n",
    "\n",
    "1. 通过`textFileStream()`读取Streaming 数据textFileStream\n",
    "2. 随着数据的更新不断训练线性回归模型\n",
    "3. 实时预测\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "import sys\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.regression import StreamingLinearRegressionWithSGD\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "\n",
    "def parse(lp):\n",
    "    label = float(lp[lp.find('(') + 1: lp.find(',')])\n",
    "    vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n",
    "    return LabeledPoint(label, vec)\n",
    "\n",
    "trainingData = ssc.textFileStream(sys.argv[1]).map(parse).cache()\n",
    "testData = ssc.textFileStream(sys.argv[2]).map(parse)\n",
    "\n",
    "numFeatures = 3\n",
    "model = StreamingLinearRegressionWithSGD()\n",
    "model.setInitialWeights([0.0, 0.0, 0.0])\n",
    "\n",
    "model.trainOn(trainingData)\n",
    "print(model.predictOnValues(testData.map(lambda lp: (lp.label, lp.features))))\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spark 中的矩阵运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### SVD 分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.mllib.linalg.distributed.RowMatrix object at 0x7f85103bb400>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "\n",
    "rows = sc.parallelize([\n",
    "    Vectors.sparse(5, {1: 1.0, 3: 7.0}),\n",
    "    Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),\n",
    "    Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0)\n",
    "])\n",
    "\n",
    "mat = RowMatrix(rows)\n",
    "\n",
    "svd = mat.computeSVD(5, computeU=True)\n",
    "U = svd.U       # The U factor is a RowMatrix.\n",
    "s = svd.s       # The singular values are stored in a local dense vector.\n",
    "V = svd.V       # The V factor is a local dense matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "rows = sc.parallelize([\n",
    "    Vectors.sparse(5, {1: 1.0, 3: 7.0}),\n",
    "    Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),\n",
    "    Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0)\n",
    "])\n",
    "\n",
    "mat = RowMatrix(rows)\n",
    "# Compute the top 4 principal components.\n",
    "# Principal components are stored in a local dense matrix.\n",
    "pc = mat.computePrincipalComponents(4)\n",
    "\n",
    "# Project the rows to the linear space spanned by the top 4 principal components.\n",
    "projected = mat.multiply(pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 上机实践\n",
    "\n",
    "- 创建并运行一个简单的Spark机器学习模型。\n",
    "\n",
    "- 了解Spark的[机器学习算法](https://spark.apache.org/docs/latest/mllib-guide.html)。\n",
    "\n",
    "- 课外阅读材料\n",
    "\n",
    "    - https://spark.apache.org/docs/latest/streaming-programming-guide.html\n",
    "    - https://spark.apache.org/docs/latest/api/python/index.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
